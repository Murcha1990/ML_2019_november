{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Loss (логарифмическая функция потерь)\n",
    "\n",
    "$$\\large logloss = - \\frac{1}{l} \\cdot \\sum_{i=1}^l (y_i \\cdot log(\\hat y_i) + (1 - y_i) \\cdot log(1 - \\hat y_i))$$\n",
    "\n",
    "здесь $\\hat y$ — это ответ алгоритма на $i$-ом объекте, $y$ — истинная метка класса на $i$-ом объекте, а $l$ размер выборки.\n",
    "\n",
    "Интуитивно можно представить минимизацию log-loss как задачу максимизации accuracy путем штрафа за неверные предсказания. Log-loss крайне сильно штрафует за уверенность классификатора в неверном ответе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss при неуверенной классификации 0.693147\n",
      "Logloss при уверенной классификации и верном ответе 0.105361\n",
      "Logloss при уверенной классификации и НЕверном ответе 2.302585\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logloss(y_true, y_pred):\n",
    "\n",
    "    return - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "\n",
    "print('Logloss при неуверенной классификации %f' % logloss(1, 0.5))\n",
    "\n",
    "print('Logloss при уверенной классификации и верном ответе %f' % logloss(1, 0.9))\n",
    "\n",
    "print('Logloss при уверенной классификации и НЕверном ответе %f' % logloss(1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, recall & confusion matrix для многоклассовой классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"CM1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"CM2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для класса Cats:\n",
    "    \n",
    "    precision = доля правильно предсказанных Cats / все предсказанные Cats = 4/13\n",
    "    \n",
    "    recall = доля правильно предсказанных Cats / все истинные Cats = 4/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1 1]\n",
      " [6 2 2]\n",
      " [3 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Cat      0.308     0.667     0.421         6\n",
      "        Fish      0.667     0.200     0.308        10\n",
      "         Hen      0.667     0.667     0.667         9\n",
      "\n",
      "   micro avg      0.480     0.480     0.480        25\n",
      "   macro avg      0.547     0.511     0.465        25\n",
      "weighted avg      0.581     0.480     0.464        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Constants\n",
    "C=\"Cat\"\n",
    "F=\"Fish\"\n",
    "H=\"Hen\"\n",
    "\n",
    "# True values\n",
    "y_true = [C,C,C,C,C,C, F,F,F,F,F,F,F,F,F,F, H,H,H,H,H,H,H,H,H]\n",
    "# Predicted values\n",
    "y_pred = [C,C,C,C,H,F, C,C,C,C,C,C,H,H,F,F, C,C,C,H,H,H,H,H,H]\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score\n",
    "\n",
    "***F1-score = 2 × (precision × recall)/(precision + recall)***\n",
    "\n",
    "F1-score - это среднее гармоническое точности и полноты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro avg (average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***macro average (precision) = среднее арифметическое всех (precision)***\n",
    "\n",
    "Пример:\n",
    "***macro avg precision = (0.308+0.667+0.667)/3=0.547***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Micro avg (average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***micro average (precision) = precision, но вычисленная на всех данных вместе.***\n",
    "\n",
    "Пример:\n",
    "precision = TP/(TP+FP)\n",
    "\n",
    "TP - все правильно предсказанные объекты: \n",
    "$$TP = 4 + 2 + 6 = 12$$\n",
    "\n",
    "FP - например, все Cat, предсказанные как Fish и т.д.\n",
    "$$FP = 6 + 3 + 1 + 0 + 1 + 2 = 13$$\n",
    "\n",
    "Поэтому\n",
    "***micro avg precision*** $ = 12/(12+13)=0.480$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cтатьи про метрики качества многоклассовой классификации:\n",
    "    \n",
    "1. https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2\n",
    "        \n",
    "2. https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
