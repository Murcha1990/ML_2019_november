{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практическая работа 2.\n",
    "\n",
    "В этой работе будем использовать датасет для классификации - определять, есть у пациента рак груди или нет. В этом датасете все признаки категориальные.\n",
    "\n",
    "Делайте те шаги задания, которые можете. Задание устроено так, что можно пропускать некоторые шаги и при этом делать следующие. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "%pylab inline\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.pca import PCA\n",
    "\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.utils.utility import precision_n_scores\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breast-cancer.data\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1.\n",
    "\n",
    "Выведите на экран первые 5 строк таблицы. Последняя (9я) колонка - целевая переменная.\n",
    "\n",
    "Также выведите на экран количество строк с ответом \"no\" и количество строк с ответом \"yes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2.\n",
    "Попытайтесь дать интерпретации тому, что содержится в колонках. Запишите словами, что по вашему мнению может содержаться в каждой колонке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your interpretation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3.\n",
    "Используйте get_dummies для кодирования столбцов 2, 5, 6, 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4.\n",
    "\n",
    "Колонки 0, 7 и 9 содержат по два категориальных значения. Закодируйте их 0 и 1.\n",
    "Например, в столбце 9 стоят 'yes' и 'no'. Замените 'yes' на 1, а 'no' на 0. Аналогично поступите с колонками 0 и 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5. \n",
    "Столбцы 1, 3 и 4 содержат несколько категорий. Закодируйте их вручную. Например, в столбце 4 категорию '0-2' замените на 0, '3-5' на 1, '6-8' на 2 и т.д. Аналогично поступите с колонками 1 и 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка\n",
    "выведите на экран таблицу с измененными колонками и проверьте, что в ней остались только числовые столбцы. Если нет, удалите нечисловые столбцы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6.\n",
    "Колонка 9 содержит целевую переменную. Создайте матрицу X объект-признак, содержащую все столбцы, кроме 9, и целевой вектор y, содержащий столбец 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7.\n",
    "Выведите качество логистической регрессии на кросс-валидации с тремя фолдами, метрика качества - accuracy. Также выведите качество на кросс-валидации SVM с а) линейным (kernel=linear), б) полиномиальным (poly), в) радиальным (rbf) ядрами. Какой алгоритм дает наилучшее качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 8.\n",
    "Попробуем удалить выбросы. Предположим, что в данных содержится 10% выбросов. В цикле примените алгоритм поиска выбросов и оставьте только объекты, не являющиеся выбросами. В этом же цикле выведите качество наилучшего алгоритма из предыдущего шага на кросс-валидации (используйте матрицу X_wo_out и вектор y_wo_out без выбросов).\n",
    "\n",
    "Какой алгоритм поиска выбросов работает на этих данных лучше всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction = 0.1\n",
    "random_state = 1\n",
    "\n",
    "classifiers = {'Cluster-based Local Outlier Factor': CBLOF(\n",
    "        contamination=outliers_fraction, check_estimator=False,\n",
    "        random_state=random_state),\n",
    "    'Feature Bagging': FeatureBagging(contamination=outliers_fraction,\n",
    "                                     random_state=random_state),\n",
    "    'Histogram-base Outlier Detection (HBOS)': HBOS(\n",
    "        contamination=outliers_fraction),\n",
    "    'Isolation Forest': IForest(contamination=outliers_fraction,\n",
    "                                random_state=random_state),\n",
    "    'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "    'Local Outlier Factor (LOF)': LOF(\n",
    "        contamination=outliers_fraction),\n",
    "    'Minimum Covariance Determinant (MCD)': MCD(\n",
    "        contamination=outliers_fraction, random_state=random_state),\n",
    "    'One-class SVM (OCSVM)': OCSVM(contamination=outliers_fraction),\n",
    "    'Principal Component Analysis (PCA)': PCA(\n",
    "        contamination=outliers_fraction, random_state=random_state),\n",
    "}\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 9.\n",
    "Теперь снизим размерность. Создайте пайплайн, в котором сначала примените PCA с 5-ю компонентами, а затем алгоритм, который лучше всего сработал в шаге 7. \n",
    "\n",
    "Выведите качество этой модели (пайплайна) на кросс-валидации. Используйте исходные данные (X, y) до удаления выбросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 10.\n",
    "Мы увидели, что и удаление выбросов, и снижение размерности увеличивает качество модели, поэтому скомбинируем шаги 8 и 9:\n",
    "    сначала удалите выбросы наилучшим алгоритмом из шага 8, а затем примените модель (пайплайн) из шага 9.\n",
    "    \n",
    "Выведите качество на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 11.\n",
    "Теперь попробуем кластеризовать наши данные (X) с помощью KMeans. Выделите в данных 2 кластера. Нарисуйте полученные точки на плоскости и раскрасьте их в цвета, соответствующие кластерам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 12.\n",
    "Разберемся, что означают кластеры:\n",
    "\n",
    "1) Нарисуйте на плоскости точки, где первая координата - признак 1, вторая - признак 3 (что это за признаки по смыслу?) и раскрасьте точки в цвета, соответствующие кластерам.\n",
    "    \n",
    "2) Теперь нарисуйте точки в координатах, соответствующих 1му и 7му признаку.\n",
    "    \n",
    "Сделайте вывод о том, какие по смыслу объекты попали в первый кластер и во второй."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
