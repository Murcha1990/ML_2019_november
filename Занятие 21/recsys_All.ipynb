{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы. Часть 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании будем практиковаться в реализации рекомендательных систем.\n",
    "\n",
    "Воспользуемся небольшим датасетом с Kaggle: [Articles Sharing and Reading from CI&T Deskdrop](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:13:51.359203Z",
     "start_time": "2019-06-08T12:13:50.732916Z"
    },
    "_cell_guid": "719f3966-e6fd-49c8-9f60-7bd741542450",
    "_uuid": "b61cd3125a7f8f991fc1bda85ae3cd26f74090ae"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f5c826d-f3d5-42d3-a7e6-0343a44cdc9f",
    "_uuid": "26f1f70fd978957b26f8884fc5f82bfe9475c666"
   },
   "source": [
    "## Часть 0. Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c48b62c-ad3b-4218-8fb2-2f0e86a16edc",
    "_uuid": "650c279eddc846a48274346e045cfb6e1f8895d5"
   },
   "source": [
    "Загрузим [Deskdrop dataset](https://www.kaggle.com/gspmoreira/articles-sharing-reading-from-cit-deskdrop), включающийся в себе логи за 1 год платформы, где пользователи читают статьи.\n",
    "\n",
    "Данные включают в себя 2 файла:  \n",
    "- **shared_articles.csv**\n",
    "- **users_interactions.csv**\n",
    "\n",
    "Как можно догадаться, в одном описания самих статей (нам понадобятся в контентных моделях), а в другом логи пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c9ee29ff-1fee-4dc9-a3cb-e5301c17fded",
    "_uuid": "1e66e976d34d4e28f5a92241b0ea82a2a66363ea"
   },
   "source": [
    "#### shared_articles.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f09d2247-a40c-4aaf-90ce-15a8721a3036",
    "_uuid": "e64f4fa8a4751274bd2d37a0f45d2d3d664d6c3e"
   },
   "source": [
    "Так как в файле перечислены даже удалённые статьи, то мы их сразу удалим (на самом деле они могли бы быть нам полезны для подсчёта различных величин, хоть мы и не можем их рекомендовать)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:16:00.406328Z",
     "start_time": "2019-06-08T12:16:00.155932Z"
    },
    "_cell_guid": "e601f966-d03f-4edc-886f-ca3d511a8045",
    "_uuid": "569c301bd128f66f29b4d97c34171e4d1712015a"
   },
   "outputs": [],
   "source": [
    "articles_df = pd.read_csv('shared_articles.csv')\n",
    "articles_df = articles_df[articles_df['eventType'] == 'CONTENT SHARED']\n",
    "articles_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "487936d5-d7b3-487d-9ef1-e3ba1e4bc421",
    "_uuid": "3f96f2d88fa86814e2fa1273d80f26d2559823fd"
   },
   "source": [
    "#### users_interactions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "325b8db8-ef44-4b59-8138-2a59bd02d66e",
    "_uuid": "86694f1b80b04b8f9b961148fb265f355f202b26"
   },
   "source": [
    "В колонке eventType описаны действия, которые могли совершать пользователи над статьёй:  \n",
    "- VIEW\n",
    "- LIKE\n",
    "- COMMENT CREATED\n",
    "- FOLLOW\n",
    "- BOOKMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:16:39.556603Z",
     "start_time": "2019-06-08T12:16:39.372857Z"
    },
    "_cell_guid": "445d39ec-f6b0-4155-9f92-0a2540918bd1",
    "_uuid": "9829842326037e364de457f832deceae074d6164"
   },
   "outputs": [],
   "source": [
    "interactions_df = pd.read_csv('users_interactions.csv')\n",
    "interactions_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:16:56.358693Z",
     "start_time": "2019-06-08T12:16:56.140532Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_df.personId = interactions_df.personId.astype(str)\n",
    "interactions_df.contentId = interactions_df.contentId.astype(str)\n",
    "articles_df.contentId = articles_df.contentId.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "585f81a5-c6ff-4399-bbec-901c41fc7285",
    "_uuid": "6abb0af8474eabb50be7a9e6496bfa75ec1b2bd9"
   },
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bad1a6c9-0258-4b89-85f9-bec89a523662",
    "_uuid": "84c2e91561d5de6afa7c45c173022193664c770e"
   },
   "source": [
    "В логах встречаются различные действия пользователей. Однако мы хотим работать лишь с одной величиной, характеризующей всё взаимодействие пользователя со статьёй. Предлагается задать действиям следующие веса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:20:34.791326Z",
     "start_time": "2019-06-08T12:20:34.786347Z"
    },
    "_cell_guid": "3239c376-05b8-4a58-9afc-f6f57f67405f",
    "_uuid": "b06f8c0b082f0ad07bf773a5ad2fae33c1f7acc2"
   },
   "outputs": [],
   "source": [
    "event_type_strength = {\n",
    "   'VIEW': 1.0,\n",
    "   'LIKE': 2.0, \n",
    "   'BOOKMARK': 2.5, \n",
    "   'FOLLOW': 3.0,\n",
    "   'COMMENT CREATED': 4.0,  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте числовую величину \"оценки\" пользователем статьи с указанными выше весами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:20:52.756645Z",
     "start_time": "2019-06-08T12:20:52.729118Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_df['eventStrength'] = interactions_df.eventType.apply(lambda x: event_type_strength[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:21:05.121038Z",
     "start_time": "2019-06-08T12:21:04.816436Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_df.eventStrength.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c92aa80-2926-44db-b358-c4c32de806c4",
    "_uuid": "91100a395fdf4fb20df02c8d248072457c980b5d"
   },
   "source": [
    "Ремендательные системы подвержены проблеме холодного старта. В рамках данного задания предлагается работать только с теми пользователями, которые взаимодействовали хотя бы с 5 материалами.\n",
    "\n",
    "Оставьте только таких пользователей. Их должно остаться 1140."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:24:08.123540Z",
     "start_time": "2019-06-08T12:24:07.977450Z"
    },
    "_cell_guid": "bad1d8ea-9b67-4a47-80c5-87a5e55c4f38",
    "_uuid": "1698c88340183baa7f3ebb8c3b60eaa8e6ca708f"
   },
   "outputs": [],
   "source": [
    "users_interactions_count_df = (\n",
    "    interactions_df\n",
    "    .groupby(['personId', 'contentId'])\n",
    "    .first()\n",
    "    .reset_index()\n",
    "    .groupby('personId').size())\n",
    "print('# users:', len(users_interactions_count_df))\n",
    "\n",
    "users_with_enough_interactions_df = \\\n",
    "    users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['personId']]\n",
    "print('# users with at least 5 interactions:',len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# users_interactions_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставьте только те взаимодействия, которые касаются только отфильтрованных пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:26:02.882360Z",
     "start_time": "2019-06-08T12:26:00.651082Z"
    },
    "_cell_guid": "4e79a418-a9d6-4e01-9f38-9b290a645626",
    "_uuid": "0f428a4c6e76f95de7ea328dc33c6539389ae5f0"
   },
   "outputs": [],
   "source": [
    "interactions_from_selected_users_df = \\\n",
    "    interactions_df.loc[\n",
    "        np.in1d(\n",
    "            interactions_df.personId,\n",
    "            users_with_enough_interactions_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:26:04.494720Z",
     "start_time": "2019-06-08T12:26:04.487165Z"
    }
   },
   "outputs": [],
   "source": [
    "print('# interactions before:', interactions_df.shape)\n",
    "print('# interactions after:', interactions_from_selected_users_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:27:28.233661Z",
     "start_time": "2019-06-08T12:27:27.916524Z"
    }
   },
   "outputs": [],
   "source": [
    "users_interactions_count_df.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной постановке каждый пользователей мог взаимодействовать с каждой статьёй более 1 раза (как минимум совершая различные действия). Предлагается \"схлопнуть\" все действия в одно взаимодействие с весом, равным сумме весов. \n",
    "\n",
    "Однако полученное число будет в том числе тем больше, чем больше действий произвёл человек. Чтобы уменьшить разброс предлагается взять логарифм от полученного числа (можно придумыват другие веса действиям и по-другому обрабатывать значения).\n",
    "\n",
    "Также сохраним последнее значение времени взаимодействия для разделениея выборки на обучение и контроль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:30:39.033711Z",
     "start_time": "2019-06-08T12:30:38.871284Z"
    },
    "_cell_guid": "54c82dd1-1102-4f11-ac6a-7993f8e5e842",
    "_uuid": "dcd64b20b47cf2c365341303ff410626a801f7a6"
   },
   "outputs": [],
   "source": [
    "def smooth_user_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "interactions_full_df = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId']).eventStrength.sum()\n",
    "    .apply(smooth_user_preference)\n",
    "    .reset_index().set_index(['personId', 'contentId'])\n",
    ")\n",
    "interactions_full_df['last_timestamp'] = (\n",
    "    interactions_from_selected_users_df\n",
    "    .groupby(['personId', 'contentId'])['timestamp'].last()\n",
    ")\n",
    "        \n",
    "interactions_full_df = interactions_full_df.reset_index()\n",
    "interactions_full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьём выборку на обучение и контроль по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:22:18.904782Z",
     "start_time": "2019-06-08T14:22:18.874059Z"
    },
    "_cell_guid": "e594a5ef-255a-4d30-9ab2-7cebe12fe798",
    "_uuid": "babda61be5306281b34422dbded67675a0aab17d"
   },
   "outputs": [],
   "source": [
    "split_ts = 1475519530\n",
    "interactions_train_df = interactions_full_df.loc[interactions_full_df.last_timestamp < split_ts].copy()\n",
    "interactions_test_df = interactions_full_df.loc[interactions_full_df.last_timestamp >= split_ts].copy()\n",
    "\n",
    "print('# interactions on Train set: %d' % len(interactions_train_df))\n",
    "print('# interactions on Test set: %d' % len(interactions_test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства подсчёта качества запишем данные в формате, где строка соответствует пользователю, а столбцы будут истинными метками и предсказанями в виде списков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:22:52.573170Z",
     "start_time": "2019-06-08T13:22:52.243792Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions = (\n",
    "    interactions_train_df\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    "    .reset_index()\n",
    "    .rename(columns={'contentId': 'true_train'})\n",
    "    .set_index('personId')\n",
    ")\n",
    "\n",
    "interactions['true_test'] = (\n",
    "    interactions_test_df\n",
    "    .groupby('personId')['contentId'].agg(lambda x: list(x))\n",
    ")\n",
    "\n",
    "# заполнение пропусков пустыми списками\n",
    "interactions.loc[pd.isnull(interactions.true_test), 'true_test'] = [\n",
    "    list() for x in range(len(interactions.loc[pd.isnull(interactions.true_test), 'true_test']))]\n",
    "\n",
    "interactions.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2fac2a15-cc5c-4f31-8818-8065b0d2dc16",
    "_uuid": "59dd2131949c4d7e801114bffc11fb439c930b4c"
   },
   "source": [
    "## Часть 1: Baseline (модель по популярности)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самой простой моделью рекомендаций (при этом достаточно сильной!) является модель, которая рекомендует наиболее популярные предметы. \n",
    "\n",
    "Предлагается реализовать её. Давайте считать, что рекомендуем мы по 10 материалов (такое ограничение на размер блока на сайте).\n",
    "\n",
    "Посчитайте популярность каждой статьи, как сумму всех \"оценок\" взаимодействий с ней. Отсортируйте материалы по их популярности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:37:19.089878Z",
     "start_time": "2019-06-08T12:37:19.076379Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:40:15.259296Z",
     "start_time": "2019-06-08T12:40:15.239253Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_content = (\n",
    "    interactions_train_df\n",
    "    .groupby('contentId')\n",
    "    .eventStrength.sum().reset_index()\n",
    "    .sort_values('eventStrength', ascending=False)\n",
    "    .contentId.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:40:17.455633Z",
     "start_time": "2019-06-08T12:40:17.448173Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо сделать предсказания для каждого пользователя. Не забывайте, что надо рекомендовать то, что пользователь ещё не читал (для этого нужно проверить, что материал не встречался в true_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:23:01.078455Z",
     "start_time": "2019-06-08T13:22:58.364762Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "\n",
    "interactions['prediction_popular'] = (\n",
    "    interactions.true_train\n",
    "    .apply(\n",
    "        lambda x:\n",
    "        popular_content[~np.in1d(popular_content, x)][:top_k]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настало время оценить качество. Посчитайте precision@10 для каждого пользователя (доля угаданных рекомендаций). Усредните по всем пользователям. Везде далее будем считать эту же метрику.\n",
    "\n",
    "(для каждого пользователя посчитаем долю правильно предсказанных статей (если в ответе их меньше 10ти, то будем нормировать на реальное количество статей))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:23:01.956777Z",
     "start_time": "2019-06-08T13:23:01.946733Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_precision(column):\n",
    "    return (\n",
    "        interactions\n",
    "        .apply(\n",
    "            lambda row:\n",
    "            len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) /\n",
    "            min(len(row['true_test']) + 0.001, 10.0),\n",
    "            axis=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:23:02.965760Z",
     "start_time": "2019-06-08T13:23:02.888095Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision('prediction_popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T12:57:37.405981Z",
     "start_time": "2019-06-08T12:57:37.396225Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions.true_test.apply(len).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Коллаборативная фильтрация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к более сложному механизму рекомендаций, а именно коллаборативной фильтрации. Суть коллаборативной фильтрации в том, что учитывается схожесть пользователей и товаров между собой, а не факторы, которые их описывают. \n",
    "\n",
    "__Предлагается на выбор реализовать один из двух подходов__: memory-based или модель со скрытыми переменные.\n",
    "\n",
    "Для начала для удобства составим матрицу \"оценок\" пользователей. Нули будут обозначать отсутствие взаимодействия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:01:37.998807Z",
     "start_time": "2019-06-08T13:01:37.836709Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = pd.pivot_table(\n",
    "    interactions_train_df,\n",
    "    values='eventStrength',\n",
    "    index='personId',\n",
    "    columns='contentId').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте схожести пользователей с помощью корреляции Пирсона. Для каждой пары учитываем только ненулевые значения.\n",
    "\n",
    "Для скорости работы лучше переходить от pandas к numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_m = ratings.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_users = np.zeros((len(ratings_m), len(ratings_m)))\n",
    "\n",
    "for i in tqdm_notebook(range(len(ratings_m)-1)):\n",
    "    for j in range(i+1, len(ratings_m)):\n",
    "        \n",
    "        # nonzero elements of two users\n",
    "        mask_uv = (ratings_m[i] != 0) & (ratings_m[j] != 0)\n",
    "        \n",
    "        # continue if no intersection\n",
    "        if np.sum(mask_uv) == 0:\n",
    "            continue\n",
    "            \n",
    "        # get nonzero elements\n",
    "        ratings_v = ratings_m[i, mask_uv]\n",
    "        ratings_u = ratings_m[j, mask_uv]\n",
    "        \n",
    "        # normalization\n",
    "        # ...\n",
    "        ratings_v = ratings_v / np.linalg.norm(ratings_v)\n",
    "        ratings_u = ratings_u / np.linalg.norm(ratings_u)\n",
    "        \n",
    "        # for nonzero std\n",
    "        if len(np.unique(ratings_v)) < 2 or len(np.unique(ratings_u)) < 2:\n",
    "            continue\n",
    "        \n",
    "        similarity_users[i,j] = np.corrcoef(ratings_u, ratings_v)[0][1]\n",
    "        similarity_users[j,i] = similarity_users[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть матрицы схожести пользователей. Их можно использовать для рекомендаций.\n",
    "\n",
    "Для каждого пользователя:\n",
    "\n",
    "1. Найдём пользователей с похожестью больше $\\alpha$ на нашего пользователя.\n",
    "2. Посчитаем для каждой статьи долю пользователей (среди выделенных на первом шаге), которые взаимодействовали со статьёй.\n",
    "3. Порекомендуем статьи с наибольшими долями со второго шага (среди тех, которые пользователь ещё не видел).\n",
    "\n",
    "В нашем примере данных не очень много, поэтому возьмём $\\alpha = 0$.\n",
    "\n",
    "После того, как будут сделаны предсказания (новый столбец в interactions), посчитайте качество по той же метрике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "alpha = 0\n",
    "Similarities = {}\n",
    "\n",
    "for i in range(len(similarity_users)):\n",
    "    Similarities[ratings.index[i]] = []\n",
    "    for j in range(len(similarity_users)):\n",
    "        if similarity_users[i,j] > alpha:\n",
    "            Similarities[ratings.index[i]].append(ratings.index[j])\n",
    "    Similarities[ratings.index[i]] = list(set(Similarities[ratings.index[i]]))\n",
    "\n",
    "#interactions['prediction_user_based'] = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь, в котором для каждого пользователя содержатся статьи, которые он смотрел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "Viewed = {}\n",
    "\n",
    "for user, row in ratings.iterrows(): \n",
    "    Viewed[user] = interactions.loc[user]['true_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viewed[ratings.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings.index - users\n",
    "# ratings.columns - articles\n",
    "\n",
    "def get_popular(user, top_k=10):\n",
    "    sim_users = ratings[ratings.index.isin(Similarities[user])] #оставляем в таблице только похожих\n",
    "    sim_users = sim_users.drop(Viewed[user], axis=1) #убираем статьи, которые user уже смотрел\n",
    "    return sim_users.astype(bool).sum(axis=0).sort_values(ascending=False).iloc[:top_k].index\n",
    "    #считаем количество взаимодействий (=ненулевых элементов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_popular(ratings.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "interactions['prediction_user_based1'] = ratings.index.map(get_popular)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "prediction_user_based = []\n",
    "for i in tqdm_notebook(range(len(similarity_users))):\n",
    "        \n",
    "    users_sim = similarity_users[i] > 0\n",
    "\n",
    "    if sum(users_sim) == 0:\n",
    "        prediction_user_based.append([])\n",
    "    else:\n",
    "        tmp_recommend = np.argsort(ratings_m[users_sim].sum(axis=0))[::-1]\n",
    "        tmp_recommend = ratings.columns[tmp_recommend]\n",
    "        recommend = np.array(tmp_recommend)[~np.in1d(tmp_recommend, interactions.iloc[i]['true_train'])][:10]\n",
    "        prediction_user_based.append(list(recommend))\n",
    "\n",
    "interactions['prediction_user_based2'] = prediction_user_based\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_precision('prediction_user_based1'), calc_precision('prediction_user_based2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель со скрытыми переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем подход с разложением матрицы оценок. Для этого сделаем сингулярное разложение (svd в scipy.linalg), на выходе получим три матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:01:07.015157Z",
     "start_time": "2019-06-08T13:01:07.011694Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:34.540295Z",
     "start_time": "2019-06-08T13:30:30.905225Z"
    }
   },
   "outputs": [],
   "source": [
    "U, sigma, V = svd(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:35.277632Z",
     "start_time": "2019-06-08T13:30:35.267532Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings.shape, U.shape, sigma.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:05:32.606058Z",
     "start_time": "2019-06-08T13:05:32.584774Z"
    }
   },
   "outputs": [],
   "source": [
    "Sigma = np.zeros((1112, 2366))\n",
    "Sigma[:1112, :1112] = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:05:36.841511Z",
     "start_time": "2019-06-08T13:05:36.334921Z"
    }
   },
   "outputs": [],
   "source": [
    "new_ratings = U.dot(Sigma).dot(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:06:04.150990Z",
     "start_time": "2019-06-08T13:06:04.112790Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(sum((new_ratings - ratings.values) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения у матрицы с сингулярными числами отсортированы по убыванию. Допустим мы хотим оставить только первые 100 компонент (и получить скрытые представления размерности 100). Для этого необходимо оставить 100 столбцов в матрице U, ***оставить из sigma только первые 100 значений (и сделать из них диагональную матрицу) и 100 столбцов в матрице V. Перемножьте преобразованные матрицы ($\\hat{U}, \\hat{sigma}, \\hat{V^T}$), чтобы получить восстановленную матрицу оценок.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:40.087895Z",
     "start_time": "2019-06-08T13:30:40.073082Z"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "Sigma = np.zeros((1112, 2366))\n",
    "sigma[100:] = 0\n",
    "Sigma[:1112, :1112] = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:41.306893Z",
     "start_time": "2019-06-08T13:30:40.899191Z"
    }
   },
   "outputs": [],
   "source": [
    "#new_ratings = #your code here\n",
    "new_ratings = U.dot(Sigma).dot(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте качество аппроксимации матрицы по норме Фробениуса (среднеквадратичную ошибку между всеми элементами соответствующими элементами двух матриц). Сравните его с простым бейзлайном с константным значением, равным среднему значению исходной матрицы. У аппроксимации ошибка должна получиться ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:42.016323Z",
     "start_time": "2019-06-08T13:30:41.979511Z"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "print(sum(sum((new_ratings - ratings.values) ** 2)))\n",
    "\n",
    "constant_ratings = np.ones(ratings.shape) * np.mean(ratings.values)\n",
    "print(sum(sum((constant_ratings - ratings.values) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:08:37.028642Z",
     "start_time": "2019-06-08T13:08:37.021010Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings.loc['-1257176162426022931', '-1022885988494278200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:44.882243Z",
     "start_time": "2019-06-08T13:30:44.877001Z"
    }
   },
   "outputs": [],
   "source": [
    "new_ratings = pd.DataFrame(\n",
    "    new_ratings, index=ratings.index, columns=ratings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:09:19.523050Z",
     "start_time": "2019-06-08T13:09:19.514586Z"
    }
   },
   "outputs": [],
   "source": [
    "new_ratings.loc['-1257176162426022931', '-1022885988494278200']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно делать предсказания по матрице. Сделайте их (не забывайте про то, что уже было просмотрено пользователем), оцените качество. Для этого необходимо для каждого пользователя найти предметы с наибольшими оценками в восстановленной матрице.\n",
    "\n",
    "Чтобы сделать предсказание для пользователя (personId):\n",
    "1. возьмите соответствующую ему строку в полученной таблице new_ratings\n",
    "2. отсортируйте рейтинги по убыванию\n",
    "3. затем возьмите индексы соответствующих столбцов (это и есть статьи) и преобразуйте их в массив\n",
    "\n",
    "Добавьте в predictions top_k статей с наибольшими рейтингами, не забудьте выкинуть статьи, которые пользователь уже видел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:52.094284Z",
     "start_time": "2019-06-08T13:30:46.974576Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for personId in tqdm_notebook(interactions.index):\n",
    "    prediction = (\n",
    "        #your code here\n",
    "        new_ratings.loc[personId].\\\n",
    "        sort_values(ascending=False).\\\n",
    "        index.values\n",
    "    )\n",
    "    \n",
    "    predictions.append(\n",
    "        #your code here\n",
    "        list(prediction[~np.in1d(prediction, interactions.loc[personId,'true_train'])])[:10]\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:53.011655Z",
     "start_time": "2019-06-08T13:30:53.001353Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions['prediction_svd'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:30:54.059500Z",
     "start_time": "2019-06-08T13:30:53.963092Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision('prediction_svd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Опционально). До этих пор мы не проводили никаких преобразований с матрицей оценок. Отцентрируйте все ненулевые (!) значения по каждому пользователю. Сделайте предсказания, посчитайте качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продублируем функцию calc_precision с добавлением параметра interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:31:19.733388Z",
     "start_time": "2019-06-08T13:31:19.726091Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_precision(interactions, column):\n",
    "    return (\n",
    "        interactions\n",
    "        .apply(\n",
    "            lambda row:\n",
    "            len(set(row['true_test']).intersection(\n",
    "                set(row[column]))) /\n",
    "            min(len(row['true_test']) + 0.001, 10.0),\n",
    "            axis=1)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доля правильных предсказаний для пользователей с 10ю и более известными рекомендациями в test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:32:21.113034Z",
     "start_time": "2019-06-08T13:32:21.090540Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision(\n",
    "    interactions.loc[interactions.true_test.apply(len) >= 10],\n",
    "    'prediction_svd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T13:32:23.462959Z",
     "start_time": "2019-06-08T13:32:23.435443Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision(\n",
    "    interactions.loc[interactions.true_test.apply(len) >= 10],\n",
    "    'prediction_popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_precision(\n",
    "    interactions.loc[interactions.true_test.apply(len) >= 10],\n",
    "    'prediction_user_based')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Контентные  модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части реализуем альтернативный подход к рекомендательным системам — контентные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы будем оперировать не матрицей с оценками, а классической для машинного обучения матрицей объекты-признаки. Каждый объект будет характеризовать пару user-item и содержать признаки, описывающие как пользователя, так и товар. Кроме этого признаки могут описывать и саму пару целиком.\n",
    "\n",
    "Матрица со всеми взаимодействиями уже получена нами на этапа разбиения выборки на 2 части. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придумаем и добавим признаков о пользователях и статьях. Сначала добавим информацию о статьях в данные о взаимодействиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_df = interactions_train_df.merge(articles_df, how='left', on='contentId')\n",
    "interactions_test_df = interactions_test_df.merge(articles_df, how='left', on='contentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first feature index\n",
    "features_start = len(interactions_train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения модели нам придётся делать предсказания на тестовой выборке для всех возможных пар статья-пользователь. Подготовим такую матрицу, чтобы параллельно посчитать признаки для неё.\n",
    "\n",
    "interactions - таблица (сделанная из interactions_train_df), где строка соответствует пользователю, а столбцы являются истинными метками и предсказанями в виде списков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:23:27.728631Z",
     "start_time": "2019-06-08T14:23:24.962680Z"
    }
   },
   "outputs": [],
   "source": [
    "test_personId = np.repeat(interactions.index, len(articles_df)) \n",
    "test_contentId = list(articles_df.contentId) * len(interactions)\n",
    "\n",
    "test = pd.DataFrame(\n",
    "    np.array([test_personId, test_contentId]).T,\n",
    "    columns=['personId', 'contentId'])\n",
    "test = test.merge(articles_df, how='left', on='contentId')\n",
    "\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотим добавить отрицательных примеров. Добавим случайные отсутствующие взаимодействия как отрицательные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_train_df = pd.concat((\n",
    "    interactions_train_df,\n",
    "    test.loc[\n",
    "        np.random.permutation(test.index)[\n",
    "            :1*len(interactions_train_df)]]), ignore_index=True)\n",
    "\n",
    "interactions_train_df.eventStrength.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте признаки-индикаторы возможных значений contentType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:23:31.640158Z",
     "start_time": "2019-06-08T14:23:31.632425Z"
    }
   },
   "outputs": [],
   "source": [
    "articles_df.contentType.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:23:35.291233Z",
     "start_time": "2019-06-08T14:23:35.282594Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:23:44.311954Z",
     "start_time": "2019-06-08T14:23:44.264057Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df['is_HTML'] = #your code here\n",
    "interactions_train_df['is_RICH'] = #your code here\n",
    "interactions_train_df['is_VIDEO'] = #your code here\n",
    "\n",
    "test['is_HTML'] = #your code here\n",
    "test['is_RICH'] = #your code here\n",
    "test['is_VIDEO'] = #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте признаки \"длина названия\" и \"длина текста\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:23:48.596017Z",
     "start_time": "2019-06-08T14:23:48.436120Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df['title_length'] = #your code here\n",
    "interactions_train_df['text_length'] = #your code here\n",
    "\n",
    "test['title_length'] = #your code here\n",
    "test['text_length'] = #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте признаки-индикаторы языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:23:52.925826Z",
     "start_time": "2019-06-08T14:23:52.893295Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:23:57.065747Z",
     "start_time": "2019-06-08T14:23:57.034779Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df['is_lang_en'] = #your code here\n",
    "interactions_train_df['is_lang_pt'] = #your code here\n",
    "\n",
    "test['is_lang_en'] = #your code here\n",
    "test['is_lang_pt'] = #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:32:17.988447Z",
     "start_time": "2019-06-08T14:32:10.118122Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df['has_new'] = #your code here\n",
    "interactions_train_df['has_why'] = #your code here\n",
    "interactions_train_df['has_how'] = #your code here\n",
    "interactions_train_df['has_ai'] = #your code here\n",
    "\n",
    "test['has_new'] = #your code here\n",
    "test['has_why'] = #your code here\n",
    "test['has_how'] = #your code here\n",
    "test['has_ai'] = #your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:33:50.615997Z",
     "start_time": "2019-06-08T14:33:50.130549Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions_train_df['popularity'] = (\n",
    "    interactions_train_df.contentId.map(\n",
    "        interactions_train_df\n",
    "        .groupby('contentId').eventStrength.sum()))\n",
    "\n",
    "test['popularity'] = (\n",
    "    test.contentId.map(\n",
    "        interactions_train_df\n",
    "        .groupby('contentId').eventStrength.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на полученных признаках градиентный бустинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:58:08.791304Z",
     "start_time": "2019-06-08T14:58:07.125587Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm \n",
    "\n",
    "regressor = lightgbm.LGBMClassifier()\n",
    "regressor.fit(interactions_train_df[interactions_train_df.columns[features_start:]],\n",
    "              interactions_train_df.eventStrength > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте предсказания на тестовой выборке, сформируйте из них рекомендации. Оцените их качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:59:09.124325Z",
     "start_time": "2019-06-08T14:58:58.885211Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = regressor.predict_proba(test[test.columns[-12:]])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:59:16.511724Z",
     "start_time": "2019-06-08T14:59:16.486847Z"
    }
   },
   "outputs": [],
   "source": [
    "test['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:55:55.119848Z",
     "start_time": "2019-06-08T14:55:55.048206Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['personId', 'contentId', 'predictions']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:59:24.937386Z",
     "start_time": "2019-06-08T14:59:24.091395Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test.sort_values('predictions', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:56:09.168451Z",
     "start_time": "2019-06-08T14:56:09.106947Z"
    }
   },
   "outputs": [],
   "source": [
    "test[['personId', 'contentId', 'predictions']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:59:31.830959Z",
     "start_time": "2019-06-08T14:59:31.489107Z"
    }
   },
   "outputs": [],
   "source": [
    "test.predictions.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:59:40.849261Z",
     "start_time": "2019-06-08T14:59:38.716133Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = test.groupby('personId')['contentId'].aggregate(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:56:34.785076Z",
     "start_time": "2019-06-08T14:56:34.765548Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:59:50.938038Z",
     "start_time": "2019-06-08T14:59:47.986843Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_predictions = []\n",
    "\n",
    "for personId in tqdm_notebook(interactions.index):\n",
    "    prediction = np.array(predictions.loc[personId])\n",
    "    \n",
    "    tmp_predictions.append(\n",
    "        list(prediction[~np.in1d(\n",
    "            prediction,\n",
    "            interactions.loc[personId, 'true_train'])])[:top_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T14:59:57.255858Z",
     "start_time": "2019-06-08T14:59:57.248859Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions['prediction_content'] = tmp_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T15:03:22.609323Z",
     "start_time": "2019-06-08T15:03:22.388605Z"
    }
   },
   "outputs": [],
   "source": [
    "interactions['prediction_both'] = \\\n",
    "    interactions.apply(\n",
    "        lambda row:\n",
    "        list(row['prediction_content'][:5]) +\n",
    "        list(row['prediction_user_based'][:5]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T15:04:06.154449Z",
     "start_time": "2019-06-08T15:04:06.052194Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision(interactions, 'prediction_popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_precision(interactions, 'prediction_user_based')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T15:00:03.726723Z",
     "start_time": "2019-06-08T15:00:03.660879Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision(interactions, 'prediction_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T15:03:29.137261Z",
     "start_time": "2019-06-08T15:03:29.061463Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision(interactions, 'prediction_both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-08T15:03:05.587248Z",
     "start_time": "2019-06-08T15:03:05.508375Z"
    }
   },
   "outputs": [],
   "source": [
    "calc_precision(interactions, 'prediction_svd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c, imp in zip(interactions_train_df.columns, regressor.feature_importances_):\n",
    "    print(c,imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Опционально) Категориальные переменные с большим количеством значений можно закодировать с помощью mean-target кодирования. Закодируйте так id статьи и пользователя. Обучите новую модель и оцените качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Факторизационные машины (опционально)\n",
    "\n",
    "Попробуем факторизационные машины из библиотеки pyFM (так как можно работать прямо из питона). https://github.com/coreylynch/pyFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к обобщению матричных разложений — факторизационным машинам, которые работают могут работать с контентной информацией. Вспомним, какие данные у нас изначально были:\n",
    "\n",
    "В факторизационную машину можно загрузить \"айдишники\" пользователей и статей (то есть сделать аналог коллаборативной фильтрации) и одновременно различные признаки.\n",
    "\n",
    "Удобно обрабатывать категориальные переменные (id и другие) можно с помощью DictVectorizer. Например, процесс может выглядить вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = [\n",
    "#     {\"user\": \"1\", \"item\": \"5\", \"age\": 19},\n",
    "#     {\"user\": \"2\", \"item\": \"43\", \"age\": 33},\n",
    "#     {\"user\": \"3\", \"item\": \"20\", \"age\": 55},\n",
    "#     {\"user\": \"4\", \"item\": \"10\", \"age\": 20},\n",
    "# ]\n",
    "# v = DictVectorizer()\n",
    "# X = v.fit_transform(train)\n",
    "# y = np.repeat(1.0, X.shape[0])\n",
    "# fm = pylibfm.FM()\n",
    "# fm.fit(X,y)\n",
    "# fm.predict(v.transform({\"user\": \"1\", \"item\": \"10\", \"age\": 24}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируйте таблицу с признаками в таком виде, где будут id пользователя, статьи и автора статьи и несколько признаков, которые вы сможете придумать. В качестве целевой переменной возьмите \"силу\" взаимодействия пользователя с каждой статьёй (помним, что у нас там все примеры по сути положительные). Запустите обучение модели на несколько итераций и сделайте предсказания. Какое качество удаётся достичь? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(interactions_train_df))):\n",
    "    features = {}\n",
    "    features['personId'] = str(interactions_train_df.iloc[i].personId)\n",
    "    features['contentId'] = str(interactions_train_df.iloc[i].contentId)\n",
    "    \n",
    "    try:\n",
    "        article = articles_df.loc[features['contentId']]\n",
    "        features['authorId'] = str(article.authorPersonId)\n",
    "        features['authorCountry'] = str(article.authorCountry)\n",
    "        features['lang'] = str(article.lang)\n",
    "        \n",
    "        #generate new features\n",
    "        \n",
    "    except:\n",
    "        features['authorId'] = 'unknown'\n",
    "        features['authorCountry'] = 'unknown'\n",
    "        features['lang'] = 'unknown'\n",
    "    \n",
    "        #generate new features\n",
    "\n",
    "    train_data.append(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим эту процедуру для тестовой выборки. Заметим, что модель оценивает каждую пару потенциального взаимодействия, а значит, надо подготовить выборку из всех возможных пар из пользователей и статей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for i in tqdm_notebook(range(len(interactions))):\n",
    "    features = {}\n",
    "    features['personId'] = str(interactions.index[i])  \n",
    "    for j in range(len(ratings.columns)):\n",
    "        features['contentId'] = str(ratings.columns[j])\n",
    "        \n",
    "        try:\n",
    "            article = articles_df.loc[features['contentId']]\n",
    "            features['authorId'] = str(article.authorPersonId)\n",
    "            features['authorCountry'] = str(article.authorCountry)\n",
    "            features['lang'] = str(article.lang)\n",
    "            \n",
    "            #add generated features\n",
    "            \n",
    "        except:\n",
    "            features['authorId'] = 'unknown'\n",
    "            features['authorCountry'] = 'unknown'\n",
    "            features['lang'] = 'unknown'\n",
    "\n",
    "            #add generated features\n",
    "\n",
    "        test_data.append(deepcopy(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем, получим разреженные матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "\n",
    "train_features = dv.fit_transform(\n",
    "    train_data + list(np.random.permutation(test_data)[:100000]))\n",
    "test_features = dv.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(interactions_train_df.eventStrength.values) + list(np.zeros(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape, len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем размер скрытого представления 10, сделаем 30 итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = pylibfm.FM(num_factors=10, num_iter=30, task='regression')\n",
    "fm.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем, оценим качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = dv.transform(test_data)\n",
    "y_predict = fm.predict(test_features)\n",
    "\n",
    "new_ratings = y_predict.reshape((1112, 2366))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i, person in enumerate(interactions.index):\n",
    "    user_prediction = ratings.columns[np.argsort(new_ratings[i])[::-1]]\n",
    "    predictions.append(\n",
    "        user_prediction[~np.in1d(user_prediction,\n",
    "                                 interactions.loc[person, 'true_train'])][:top_k])\n",
    "    \n",
    "interactions['fm_prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_precision('fm_prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Опционально) Попробуйте добавить случайные негативные примеры из статей, с которыми пользователь не взаимодействовал. Какое качество удалось достичь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
