{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA (Linear Discriminant Analysis). Сравнение LDA и PCA. Тематическое моделирование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#запустить эту ячейку до начала занятия\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA,LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Главное отличие LDA от PCA: LDA - это алгоритм обучения с учителем, а PCA - нет.\n",
    "\n",
    "PCA находит направления с максимальной дисперсией и проектирует данные на эти направления.\n",
    "LDA создает новую ось таким образом, что при проецировании данных на эту ось объекты двух классов максимально разделяются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iris = load_iris()\n",
    "\n",
    "data = Iris.data\n",
    "target = Iris.target\n",
    "target_names = Iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.concatenate((data,target.reshape(150,1)),axis=1),\\\n",
    "                  columns=['col_1','col_2','col_3','col_4','target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['target'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_feature_reduced = pca.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_feature_reduced[:,0], X_feature_reduced[:,1], c=target)\n",
    "plt.title(\"PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=2)\n",
    "\n",
    "X_feature_reduced2 = lda.fit(df, target).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_feature_reduced2[:,0], X_feature_reduced2[:,1], c=target)\n",
    "plt.title('LDA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдение**\n",
    "\n",
    "Мы видим, что LDA проектирует данные на такую новую ось, что классы максимально разделены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тематическое моделирование (topic modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование - это присваивание темы (topic) каждому документу. Каждая тема представлена определенными словами.\n",
    "\n",
    "Рассмотрим пример:\n",
    "\n",
    "У нас есть два топика: топик 1 и топик 2. Топик1 представлен словами \"apple, banana, mange\",\n",
    "топик2 - словами \"tennis, cricket, hockey\". Можем предположить, что в топике1 речь идет о фруктах, а в топике2 - о спорте. Затем каждому новому документу мы присваиваем одну из этих тем (топик1 или топик2).\n",
    "\n",
    "Другой пример: предположим, у нас есть 6 документов\n",
    "\n",
    "apple banana\n",
    "apple orange\n",
    "banana orange\n",
    "tiger cat\n",
    "tiger dog\n",
    "cat dog\n",
    "\n",
    "Что будет происходить с тематическим моделированием, если мы захотим извлечь две темы (два топика) из этих документов?\n",
    "Мы получим два распределения: распределение тема-слово (topic-word) и распределение документ-тема (doc-topic).\n",
    "\n",
    "Идеальное распределение документ-слово в данном примере будет таким:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![How](df1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идеальное распределение документ-тема будет таким:\n",
    "\n",
    "![How](df2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что у нас есть новый документ \"cat dog apple\", тогда его представление по темам должно быть следующим:\n",
    "\n",
    "Topic1: 0.33\n",
    "\n",
    "Topic2: 0.66\n",
    "\n",
    "LDA широко применяется в таких задачах. Его использование для тематического моделирования продемонстрировано ниже. \n",
    "\n",
    "Мы подаем на вход LDA число тем (topics), которые хотим выделить в корпусе. \n",
    "\n",
    "Но сначала необходимо векторизовать слова (будем использовать подход - мешок слов), поэтому взаимосвязь между словами в текстах при таком подходе исчезнет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() #For words Lemmatization\n",
    "stemmer = PorterStemmer()  #For stemming words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TokenizeText(text):\n",
    "    ''' \n",
    "     Tokenizes text by removing various stopwords and lemmatizing them\n",
    "    '''\n",
    "    text=re.sub('[^A-Za-z0-9\\s]+', '', text)\n",
    "    word_list=word_tokenize(text)\n",
    "    word_list_final=[]\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word not in stop_words:\n",
    "            word_list_final.append(lemmatizer.lemmatize(word))\n",
    "    return word_list_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettopicwords(topics, cv, n_words=10):\n",
    "    '''\n",
    "        Print top n_words for each topic.\n",
    "        cv=Countvectorizer\n",
    "    '''\n",
    "    for i, topic in enumerate(topics):\n",
    "        top_words_array = np.array(cv.get_feature_names())[np.argsort(topic)[::-1][:n_words]]\n",
    "        print(\"For  topic {} it's top {} words are \".format(str(i),str(n_words)))\n",
    "             \n",
    "        combined_sentence=\"\"\n",
    "        for word in top_words_array:\n",
    "            combined_sentence+=word+\" \"\n",
    "        print(combined_sentence)\n",
    "#        print(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('million-headlines.zip',usecols=[1])\n",
    "df = df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data link:\n",
    "\n",
    "https://www.kaggle.com/therohk/million-headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "num_features = 100000\n",
    "# cv=CountVectorizer(min_df=0.01,max_df=0.97,tokenizer=TokenizeText,max_features=num_features)\n",
    "cv = CountVectorizer(tokenizer=TokenizeText, max_features=num_features)\n",
    "transformed_data = cv.fit_transform(df['headline_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "no_topics=10  ## We can change this, hyperparameter\n",
    "lda = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', \\\n",
    "                                learning_offset=50.,random_state=0, n_jobs=-1).fit(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lda.components_ - это таблица тема-слово, она показывает, какими словами представлена каждая тема."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For  topic 0 it's top 10 words are \n",
      "crash sars woman new lead final car dead clash strike \n",
      "For  topic 1 it's top 10 words are \n",
      "iraqi force plan three missing case missile open air denies \n",
      "For  topic 2 it's top 10 words are \n",
      "u iraq war say troop anti get fire australia wa \n",
      "For  topic 3 it's top 10 words are \n",
      "back killed set nsw coalition home minister year election korea \n",
      "For  topic 4 it's top 10 words are \n",
      "man police face court vic take two charge charged coast \n",
      "For  topic 5 it's top 10 words are \n",
      "world saddam pm dy cup melbourne former stay power blue \n",
      "For  topic 6 it's top 10 words are \n",
      "win say protest marine found union make battle probe accident \n",
      "For  topic 7 it's top 10 words are \n",
      "baghdad may hospital hit group support concern seek ban inquiry \n",
      "For  topic 8 it's top 10 words are \n",
      "council govt death claim police plan qld new water hope \n",
      "For  topic 9 it's top 10 words are \n",
      "call report attack begin bridge near work appeal rail put \n"
     ]
    }
   ],
   "source": [
    "gettopicwords(lda.components_,cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присваивание темы документу\n",
    "\n",
    "Можно заметить, что каждый документ содержит комбинацию тем. Посмотрим на темы первых десяти документов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['headline_text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for doc in docs:\n",
    "    data.append(lda.transform(cv.transform([doc])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['topic'+str(i) for i in range(1,11)]\n",
    "doc_topic_df = pd.DataFrame(columns=cols, data=np.array(data).reshape((10,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_df['major_topic'] = doc_topic_df.idxmax(axis=1)\n",
    "doc_topic_df['raw_doc'] = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>major_topic</th>\n",
       "      <th>raw_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>topic4</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.871428</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>topic3</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.183334</td>\n",
       "      <td>topic1</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.589972</td>\n",
       "      <td>0.185016</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012512</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>topic1</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.165426</td>\n",
       "      <td>0.720289</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>topic2</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>topic7</td>\n",
       "      <td>ambitious olsson wins triple jump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.183327</td>\n",
       "      <td>0.516662</td>\n",
       "      <td>0.183341</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>topic8</td>\n",
       "      <td>antic delighted with record breaking barca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.137503</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.762492</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>topic9</td>\n",
       "      <td>aussie qualifier stosur wastes four memphis match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.871420</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>topic3</td>\n",
       "      <td>aust addresses un security council over iraq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.849988</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>topic3</td>\n",
       "      <td>australia is locked into war timetable opp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic1    topic2    topic3    topic4    topic5    topic6    topic7  \\\n",
       "0  0.016667  0.016667  0.016667  0.850000  0.016667  0.016667  0.016667   \n",
       "1  0.014286  0.014286  0.871428  0.014286  0.014286  0.014286  0.014286   \n",
       "2  0.683333  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667   \n",
       "3  0.589972  0.185016  0.137500  0.012500  0.012500  0.012500  0.012500   \n",
       "4  0.165426  0.720289  0.014286  0.014286  0.014286  0.014286  0.014286   \n",
       "5  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.850000   \n",
       "6  0.016667  0.016667  0.016667  0.016667  0.016670  0.016667  0.183327   \n",
       "7  0.012505  0.137503  0.012500  0.012500  0.012500  0.012500  0.012500   \n",
       "8  0.014286  0.014286  0.871420  0.014286  0.014287  0.014286  0.014286   \n",
       "9  0.016667  0.016667  0.849988  0.016676  0.016667  0.016667  0.016670   \n",
       "\n",
       "     topic8    topic9   topic10 major_topic  \\\n",
       "0  0.016667  0.016667  0.016667      topic4   \n",
       "1  0.014286  0.014286  0.014286      topic3   \n",
       "2  0.016667  0.016667  0.183334      topic1   \n",
       "3  0.012500  0.012512  0.012500      topic1   \n",
       "4  0.014286  0.014286  0.014286      topic2   \n",
       "5  0.016667  0.016667  0.016667      topic7   \n",
       "6  0.516662  0.183341  0.016667      topic8   \n",
       "7  0.012500  0.762492  0.012500      topic9   \n",
       "8  0.014286  0.014293  0.014286      topic3   \n",
       "9  0.016667  0.016667  0.016667      topic3   \n",
       "\n",
       "                                             raw_doc  \n",
       "0  aba decides against community broadcasting lic...  \n",
       "1     act fire witnesses must be aware of defamation  \n",
       "2     a g calls for infrastructure protection summit  \n",
       "3           air nz staff in aust strike for pay rise  \n",
       "4      air nz strike to affect australian travellers  \n",
       "5                  ambitious olsson wins triple jump  \n",
       "6         antic delighted with record breaking barca  \n",
       "7  aussie qualifier stosur wastes four memphis match  \n",
       "8       aust addresses un security council over iraq  \n",
       "9         australia is locked into war timetable opp  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы увидели, как LDA может быть использован для тематического моделирования. Такой подход также может быть применен для кластеризации документов, основанной на группировке по темам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылки\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/\n",
    "\n",
    "https://sebastianraschka.com/faq/docs/lda-vs-pca.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
